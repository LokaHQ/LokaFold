{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlphaPickle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NpoCLRsSixOnBJO_39VQhzHCXAikJIhN",
      "authorship_tag": "ABX9TyOEbmbnFU1d9/YAbuRCpFVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattarnoldbio/alphapickle/blob/main/AlphaPickle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AlphaPickle: making AlphaFold2 outputs interpretable\n",
        "\n",
        "AlphaPickle is multipurpose Python script for producing plots and user-legible files from the output of [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) \\([notebook](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb)\\) and [Colabfold](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v2) \\([notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb#scrollTo=UGUBLzB3C6WN)\\).\n",
        "\n",
        "The functions provided here aim to tackle the problem of output metadata from these programs being difficult to process for users who don't have Python training. Currently, PAE outputs from AlphaFold 2.1.0 are in the form of .pkl files, which can only be read using a Python script. For data from AlphaFold DB and ColabFold, these data are in .json format (not typically easy to process for non-code writing users). \n",
        "\n",
        "For all of the above software, pLDDT values are outputted in the B-factor field of the PDB file for each prediction. This is very useful for visualisation (e.g. using the ChimeraX command `color bfactor palette alphafold`), but may be difficult in terms of customisable visualisation for non-code writing users.\n",
        "\n",
        "This collection of code will take any of the above output files and provide a .csv file (which can be opened and used for plotting in Excel, Numbers, Google Sheets) as well as a downloadable plot.\n",
        "\n",
        "To use, please run every cell in order (or select Runtime > Run all). When prompted, select as many files of the given type (Please upload PAE files and pLDDT files separately) as you wish in the file browser."
      ],
      "metadata": {
        "id": "0Fb-XoehRWQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jQUP8Ab3RN7s"
      },
      "outputs": [],
      "source": [
        "#@title Import modules and define classes and functions\n",
        "#@markdown Please run this cell first to prepare the python environment.\n",
        "import google.colab\n",
        "import sys\n",
        "# sys.path.insert(0, \"/usr/local/lib/python3.7/site-packages/\")\n",
        "!/usr/bin/yes | pip -q uninstall matplotlib 1> tmp 2> null\n",
        "!/usr/bin/yes | pip install --upgrade --quiet numpy scipy matplotlib==3.1.3 biopython 1> tmp 2> null\n",
        "\n",
        "import pickle as pkl\n",
        "#from zipfile import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt ,colors as cols ,cm as cm\n",
        "import json\n",
        "from sys import exit\n",
        "import os\n",
        "from Bio import PDB as pdb \n",
        "import io\n",
        "\n",
        "\n",
        "# Define class for AlphaFold metadata file and class methods\n",
        "class AlphaFoldMetaData(object):\n",
        "    def __init__(self, PathToFile, FastaSequence=None, ranking=None):\n",
        "        # Define attributes\n",
        "        self.PathToFile = PathToFile\n",
        "        self.FastaSequence = FastaSequence\n",
        "        self.saving_filename = self.PathToFile.split(\"/\")[-1].split(\".\")[0]\n",
        "        self.saving_pathname = self.PathToFile.split(self.saving_filename)[0]\n",
        "        if ranking:\n",
        "            self.saving_filename = \"ranked_{}\".format(ranking)\n",
        "\n",
        "\n",
        "     # Generate a plot of pLDDT value\n",
        "    def plot_pLDDT(self, size_in_inches=12, axis_label_increment=100):\n",
        "        x = list(range(0,len(self.pLDDT),1))\n",
        "        y = list(self.pLDDT)\n",
        "\n",
        "        # Use standard AlphaFold colors \n",
        "        cmap = cols.LinearSegmentedColormap.from_list(\"\", [\"red\",\"orange\",\"yellow\",\"cornflowerblue\",\"blue\"])\n",
        "\n",
        "        plt.figure(figsize=(size_in_inches,(size_in_inches/2)))\n",
        "        ticks = np.arange(0, len(self.pLDDT), axis_label_increment)\n",
        "        plt.xticks(ticks, fontname=\"Helvetica\")\n",
        "        plt.yticks(fontname=\"Helvetica\")\n",
        "        plt.xlabel(\"Residue index\", size=14, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        plt.ylabel(\"Predicted LDDT\",size=14, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        plt.scatter(x,y, c=y, cmap=cmap, s=5) \n",
        "        plt.clim(0,100)\n",
        "        scale = plt.colorbar(shrink=0.5)\n",
        "        scale.set_label(label=\"Predicted LDDT\",size=12, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        # Save to directory with pickle file in\n",
        "        plt.savefig('{}/{}_pLDDT.png'.format(self.saving_pathname, self.saving_filename), dpi=300)\n",
        "\n",
        "        # Generate a plot from PAE measurements\n",
        "    def plot_PAE(self, size_in_inches=12, axis_label_increment=100):\n",
        "        ticks = np.arange(0, self.PAE[1].size, axis_label_increment)\n",
        "        plt.figure(figsize=(size_in_inches,size_in_inches))\n",
        "        PAE = plt.imshow(self.PAE)\n",
        "        plt.xticks(ticks, fontname=\"Helvetica\")\n",
        "        plt.yticks(ticks, fontname=\"Helvetica\")\n",
        "        plt.xlabel(\"Residue index\", size=14, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        plt.ylabel(\"Residue index\", size=14, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        scale = plt.colorbar(PAE, shrink=0.5)\n",
        "        scale.set_label(label=\"Predicted error (Ã…)\",size=12, fontweight=\"bold\", fontname=\"Helvetica\")\n",
        "        \n",
        "        # Save plot\n",
        "        plt.savefig('{}/{}_PAE.png'.format(self.saving_pathname, self.saving_filename),dpi=300)\n",
        "\n",
        "        # Generate dataframe from PAE data and save to csv\n",
        "        pd_PAE = pd.DataFrame(self.PAE)\n",
        "        pd_PAE.to_csv('{}/{}_PAE.csv'.format(self.saving_pathname, self.saving_filename))\n",
        "\n",
        "\n",
        "class AlphaFoldPickle(AlphaFoldMetaData):\n",
        "\n",
        "    def __init__(self, PathToFile, FastaSequence=None, ranking=None):\n",
        "        super().__init__(PathToFile, FastaSequence, ranking)        # Define attributes\n",
        "        if ranking:\n",
        "            self.saving_filename = \"ranked_{}\".format(ranking)\n",
        "        self.data = []\n",
        "        self.PAE = None\n",
        "\n",
        "        # Extract pickled data\n",
        "        with (open(\"{}\".format(self.PathToFile), \"rb\")) as openfile:\n",
        "            while True:\n",
        "                try:\n",
        "                    self.data.append(pkl.load(openfile))\n",
        "                except EOFError:\n",
        "                    break\n",
        "\n",
        "        # Try statement accounts for data run using non-pTM models, with no PAE output\n",
        "        try:\n",
        "            self.PAE = self.data[0]['predicted_aligned_error']\n",
        "        except:\n",
        "            print(\"PAE model data not present. To access this performance metric, run AlphaFold\"\n",
        "            \"using pTM-enabled models.\")\n",
        "\n",
        "        # Define pLDDT\n",
        "        self.pLDDT = self.data[0]['plddt']\n",
        "\n",
        "\n",
        "\n",
        "    # Generate a ChimeraX attribute file from pLDDT measurements   \n",
        "    def write_pLDDT_file(self):\n",
        "        seqMismatch = False\n",
        "        pd_lDDT = pd.DataFrame(self.pLDDT)\n",
        "                # Name dataframe column\n",
        "        pd_lDDT.columns= [\"pLDDT\"]\n",
        "\n",
        "        # If the fasta file was provided:\n",
        "        if self.FastaSequence != None:\n",
        "            \n",
        "            # Open the fasta file in read mode\n",
        "            with (open(\"{}\".format(self.FastaSequence), \"r\")) as openfile:\n",
        "                fasta = openfile.read()\n",
        "\n",
        "            # Delete header line and remove line-breaks\n",
        "            sequence = fasta.split(\"\\n\",1)[1].replace(\"\\n\",\"\")\n",
        "\n",
        "            # Check that the lengths of the two sequences match\n",
        "            if len(sequence) != len(pd_lDDT):\n",
        "\n",
        "                # If not, ignore the fasta file\n",
        "                print(\"Length of sequence in fasta file provided ({}) does not match length of sequence used in AlphaFold prediction ({}). Ignoring fasta file.\".format(len(sequence),len(pd_lDDT)))\n",
        "                seqMismatch = True\n",
        "            # If they do,\n",
        "            else:\n",
        "                # Convert the fasta sequence into a residue list\n",
        "                list_sequence = []\n",
        "                for item in sequence: \n",
        "                    list_sequence.append(item)\n",
        "\n",
        "                # Convert the list into a pandas series\n",
        "                pd_sequence = pd.Series(list_sequence)\n",
        "\n",
        "                # Insert the series into the dataframe at column 1 to act as labels for the data\n",
        "                pd_lDDT.insert(0,\"Residue\",pd_sequence)\n",
        "\n",
        "        # Otherwise, remind user to check that they have used corret input files\n",
        "        else:\n",
        "            print(\"Number of residues for which pLDDT is provided: \", len(pd_lDDT), \n",
        "            \"If this does not match the length of your sequence, please double check the input file.\")\n",
        "\n",
        "\n",
        "\n",
        "        # Tell python not to elide middle rows of dataframe when printing to std.out\n",
        "        pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "        # Save dataframe to ./outputfiles with same name as original pickle and .csv extension\n",
        "        pd_lDDT.to_csv('{}/{}_pLDDT.csv'.format(self.saving_pathname, self.saving_filename))\n",
        "        # Delete residue ID\n",
        "        if self.FastaSequence != None and seqMismatch == False:\n",
        "            lDDT_table = pd_lDDT.drop('Residue', axis=1)\n",
        "        else:\n",
        "            lDDT_table = pd_lDDT\n",
        "\n",
        "        # Initialise list to store Chimera-style residue identifiers (\":x\", where x = residue number)\n",
        "        residue_list = []\n",
        "\n",
        "        # Populate this list\n",
        "        for residue in range(0,len(lDDT_table)):\n",
        "            residue_list.append(\":{}\".format(residue+1))\n",
        "\n",
        "        # Save to pandas format\n",
        "        chimerax_numbering = pd.Series(residue_list)\n",
        "\n",
        "        # Insert in the first column of the dataframe, to satisfy ChimeraX formatting\n",
        "        lDDT_table.insert(0, 'Numbering', chimerax_numbering)\n",
        "\n",
        "        # Tidy indices so the first label is 1 not 0\n",
        "        pd_lDDT.index += 1\n",
        "\n",
        "        # Create a file to save the Chimera attribute output into\n",
        "\n",
        "        with (open('{}/{}_lDDT.txt'.format(self.saving_pathname, self.saving_filename),'w+')) as openfile:\n",
        "\n",
        "            # Write file header in correct format\n",
        "            openfile.write('attribute: pLDDTvalue\\nmatch mode: 1-to-1\\nrecipient: residues\\n')\n",
        "\n",
        "            # Iterate over rows of dataframe, writing residue ID and lDDT value to file with correct formatting\n",
        "            for i,row in lDDT_table.iterrows():\n",
        "                openfile.write(\"\\t{}\\t{}\\n\".format(row['Numbering'],row['pLDDT']))\n",
        "\n",
        "        return pd_lDDT\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "class AlphaFoldJson:\n",
        "    def __init__(self, PathToDirectory):\n",
        "        self.PathToDirectory = PathToDirectory\n",
        "        self.RankingDebug = []\n",
        "        try:\n",
        "            with open(\"{}/ranking_debug.json\".format(self.PathToDirectory)) as jsonfile:\n",
        "                self.RankingDebugRaw = json.load(jsonfile)\n",
        "            for index in enumerate(self.RankingDebugRaw['order']):\n",
        "                self.RankingDebug.append(index)\n",
        "        except:\n",
        "            exit(\"To use batch processing, please ensure that the ranking_debug.json file and the result_model_n.pkl files are present in the directory issued in the command. Exiting AlphaPickle now...\")\n",
        "\n",
        "\n",
        "class AlphaFoldPDB(AlphaFoldMetaData):\n",
        "    def loadCleanStructure(self,  id, filePath):\n",
        "        standardResidues = [\"ALA\",\"ARG\",\"ASN\",\"ASP\",\"CYS\",\"GLU\",\"GLN\",\"GLY\",\"HIS\",\"ILE\",\"LEU\",\"LYS\",\"MET\",\"PHE\",\"PRO\",\"SER\",\"THR\",\"TRP\",\"TYR\",\"VAL\"]\n",
        "\n",
        "        parser = pdb.PDBParser()\n",
        "        parsedStructure = parser.get_structure(id, filePath)\n",
        "        for chain in parsedStructure.get_chains():\n",
        "            removeResidues = list()\n",
        "            for i, residue in enumerate(chain.get_residues()):\n",
        "                if residue.resname not in standardResidues:\n",
        "                    removeResidues.append(residue.id)\n",
        "                    print(residue.id)\n",
        "            [chain.detach_child(id) for id in removeResidues]\n",
        "    \n",
        "        return parsedStructure\n",
        "\n",
        "\n",
        "    def extractPLDDT(self, PDBobject):\n",
        "        pLDDT = []\n",
        "        for residue in PDBobject.get_residues():\n",
        "            i = 0\n",
        "            for atom in residue.get_atoms():\n",
        "                while i < 1:\n",
        "                    pLDDT.append(atom.bfactor)\n",
        "                    i+=1\n",
        "        pLDDT_series = pd.Series(pLDDT)\n",
        "        return pLDDT_series\n",
        "\n",
        "    def __init__(self, PathToFile, FastaSequence=None, ranking=None):\n",
        "        super().__init__(PathToFile,FastaSequence,ranking)\n",
        "        # Define attributes\n",
        "        if ranking:\n",
        "            self.saving_filename = \"ranked_{}\".format(ranking)\n",
        "        self.structure = self.loadCleanStructure(\"test\", PathToFile)\n",
        "        self.pLDDT = self.extractPLDDT(self.structure)\n",
        "        self.data = []\n",
        "        self.PAE = None\n",
        "\n",
        "\n",
        "    def PDB_write_pLDDT(self):\n",
        "        residueNumbers = pd.Series(range(1,len(self.pLDDT)+1))\n",
        "        if len(residueNumbers) != len(self.pLDDT):\n",
        "            print(\"Oops\")\n",
        "        else:\n",
        "            pd_lDDT = pd.DataFrame(self.pLDDT)\n",
        "            pd_lDDT.columns= [\"pLDDT\"]\n",
        "            pd_lDDT.insert(0,\"Residue\",residueNumbers)\n",
        "            pd_lDDT.to_csv('{}/{}_pLDDT.csv'.format(self.saving_pathname, self.saving_filename))\n",
        "\n",
        "class AlphaFoldPAEJson(AlphaFoldMetaData):\n",
        "    def extractPAEfromJson(self, PathToFile):\n",
        "        \n",
        "        with open(PathToFile, 'r') as file:\n",
        "            jsonstring = json.load(file)\n",
        "\n",
        "            residue1 = jsonstring[0]['residue1']\n",
        "            residue2 = jsonstring[0]['residue2']\n",
        "            pae = jsonstring[0]['distance']\n",
        "\n",
        "\n",
        "        paeArray = np.ones((max(residue1),(max(residue2))))\n",
        "\n",
        "        for i, j, n in zip(residue1,residue2,pae):\n",
        "            paeArray[int(i-1),int(j-1)] = n\n",
        "\n",
        "        return paeArray\n",
        "\n",
        "    def __init__(self, PathToFile, FastaSequence=None, ranking=None):\n",
        "        super().__init__(PathToFile,FastaSequence,ranking)\n",
        "        if ranking:\n",
        "            self.saving_filename = \"ranked_{}\".format(ranking)\n",
        "\n",
        "        self.PAE = self.extractPAEfromJson(PathToFile)\n",
        "        self.pLDDT = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload files\n",
        "#@markdown Upload as many metadata files as you need to process here. The program will prompt for two separate uploads: \n",
        "#@markdown - PAE files: select multiple files containing PAE data of either (or a mixture of) .pkl or .json format. If this function is not desired, press cancel upload.\n",
        "#@markdown - pLDDT files: select multiple files containing pLDDT data of either (or a mixture of) .pkl or .pdb format. If this function is not desired, press cancel upload.\n",
        "\n",
        "print(\"Select PAE files for upload\")\n",
        "PAEfiles =  list(google.colab.files.upload().keys())\n",
        "print(\"Select pLDDT files for upload\")\n",
        "pLDDTfiles =  list(google.colab.files.upload().keys())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bJKq_dtHhoOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process files\n",
        "#@markdown Input parameters for plotting here. The program will plot all of the previously uploaded files and save the metadata values to a .csv file, for easy legibility and downstream processing.\n",
        "\n",
        "#@markdown Don't worry about copying and pasting plots; the outputs can all be downloaded below.\n",
        "\n",
        "#@markdown Input desired plot size, in inches.\n",
        "plot_size =  12 #@param{type: \"integer\"} \n",
        "\n",
        "#@markdown Input value to increment plot axes by (this may need finetuning based on output)\n",
        "plot_increment = \"50\" #@param[10,25,50,100,250,500]\n",
        "plot_increment = int(plot_increment)\n",
        "\n",
        "filesForDownload = []\n",
        "\n",
        "for PAEfile in PAEfiles:\n",
        "  fileType = PAEfile.split(\".\")[-1]\n",
        "  fileName = PAEfile.split(\".\")[0]\n",
        "  if fileType == \"pkl\":\n",
        "    results = AlphaFoldPickle(PAEfile,None)\n",
        "    results.saving_pathname = os.getcwd()\n",
        "    results.saving_filename = fileName\n",
        "    if type(results.PAE) == np.ndarray:\n",
        "            print(\"Plotting PAE for {} and saving to csv\".format(PAEfile))\n",
        "            results.plot_PAE(size_in_inches=plot_size, axis_label_increment= plot_increment)\n",
        "    filesForDownload.extend([\"{}_PAE.png\".format(results.saving_filename),\"{}_PAE.csv\".format(results.saving_filename)])\n",
        "  if fileType == \"json\":\n",
        "    results = AlphaFoldPAEJson(PAEfile)\n",
        "    results.saving_filename = fileName\n",
        "    results.saving_pathname = os.getcwd()\n",
        "    print(\"Plotting for {} and saving to csv\".format(PAEfile))\n",
        "    results.plot_PAE(size_in_inches=plot_size, axis_label_increment= plot_increment)\n",
        "    filesForDownload.extend([\"{}_PAE.png\".format(results.saving_filename),\"{}_PAE.csv\".format(results.saving_filename)])\n",
        "  else:\n",
        "    raise TypeError(\"Expected file of type .pkl or .json. Check the extensions of uploaded PAE files match one of these and rerun the upload step.\")\n",
        "\n",
        "\n",
        "for pLDDTfile in pLDDTfiles:\n",
        "  fileType = pLDDTfile.split(\".\")[-1]\n",
        "  fileName = pLDDTfile.split(\".\")[0]\n",
        "  if fileType == \"pkl\":\n",
        "    results = AlphaFoldPickle(pLDDTfile, None)\n",
        "    results.saving_filename = fileName\n",
        "    results.saving_pathname = os.getcwd()\n",
        "    results.PDB_write_pLDDT()\n",
        "    print(\"Plotting pLDDT for {} and saving to csv\".format(pLDDTfile))\n",
        "    results.plot_pLDDT(size_in_inches=plot_size, axis_label_increment=plot_increment)\n",
        "    filesForDownload.extend([\"{}_pLDDT.png\".format(results.saving_filename),\"{}_pLDDT.csv\".format(results.saving_filename)])\n",
        "  if fileType == \"pdb\":\n",
        "     results = AlphaFoldPDB(pLDDTfile)\n",
        "     results.saving_filename = fileName\n",
        "     results.saving_pathname = os.getcwd()\n",
        "     print(\"Plotting pLDDT for {} and saving to csv\".format(pLDDTfile))\n",
        "     results.PDB_write_pLDDT()\n",
        "     results.plot_pLDDT(size_in_inches=plot_size, axis_label_increment=plot_increment)\n",
        "     filesForDownload.extend([\"{}_pLDDT.png\".format(results.saving_filename),\"{}_pLDDT.csv\".format(results.saving_filename)])\n",
        "  else:\n",
        "    raise TypeError(\"Expected file of type .pkl or .pdb. Check the extensions of uploaded pLDDT files match one of these and rerun the upload step.\")\n",
        "  \n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JC0OCs066PTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compress and download files\n",
        "\n",
        "with open(\"tempfile.txt\",\"w\") as tempfile:\n",
        "  for item in filesForDownload:\n",
        "    tempfile.write(item)\n",
        "    tempfile.write(\"\\n\")\n",
        "\n",
        "!DATE=$(date +%H%M%S);echo $DATE;DIR=AlphaPickleOut; FILESTR=$(echo $DIR$DATE);echo $FILESTR; mkdir $FILESTR; cat tempfile.txt | while read line; do mv $line ./$FILESTR/$line; done; tar czvf ./$FILESTR.zip $FILESTR; echo $FILESTR.zip > downloadTMP.txt\n",
        "\n",
        "with open(\"downloadTMP.txt\", \"r\") as tmp:\n",
        "  download = tmp.readline().split(\"\\n\")[0]\n",
        "\n",
        "google.colab.files.download(download)\n",
        "    "
      ],
      "metadata": {
        "id": "eqcVlG_QEWnB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}